# 1. 論文の要旨
## 1.1. 論文情報
- タイトル：[Detecting Pretraining Data from Large Language Models](https://openreview.net/forum?id=zWqr3MQuNs) (ICLR 2024)
- 著者：Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, Luke Zettlemoyer

## 1.2. 概要
この論文は、与えられたテキストが大規模言語モデル（LLM）の事前学習データに含まれるかを検出するメンバーシップ推論攻撃（MIA）について研究している。LLMは広く使用されているが、学習に使用されたデータはほとんど公開されていない。この研究では、与えられたテキストがモデルの事前学習データに含まれているかどうかを検出する新しいMIA「MIN-K% PROB」を提案しており、さらにMIA手法の評価ベンチマーク「WIKIMIA」を構築している。

## 1.3. 貢献
### 貢献1：WIKIMIAベンチマークの構築
以前までは、複数のMIA手法を比較するための汎用的なベンチマークはなかった。そこで本研究は、MIA手法を評価するためのベンチマークとして[WIKIMIA](https://huggingface.co/datasets/swj0419/WikiMIA)を構築している。WIKIMIAは次の特徴を持つ：
- **正確性**: LLMの事前学習前のデータと後のデータを使用しているため、学習データと非学習データを明確に区別。
- **汎用性**: Wikipediaデータを使用しているため、多くのモデル（例：LLaMA, GPT-Neo, OPT）に適用可能。
- **動的更新**: 新しい非学習データを自動的に収集できるため、動的にベンチマークを更新可能。

### 貢献2：新しいメンバーシップ推論方法MIN-K% PROBの提案
既存のMIA手法である[LOSS Attack](https://ieeexplore.ieee.org/document/8429311)は、長さ$n$のテキスト$x=(x_1,\ldots,x_n)$と言語モデル$f_\theta$が与えれられた時、テキスト$x$の損失（負の対数尤度）が特定の閾値$\tau$より小さいときに、$x$が学習済みであると判定する：
$$ -\frac{1}{n}\sum_{i=1}^n p_\theta(x_i|x_1,\ldots,x_{i-1}) < \tau $$
一般に、機械学習モデルは学習データの損失が小さくなるように学習するため、その観点ではLOSS Attackは合理的なMIA手法と言える。

MIN-K% PROBはLOSS Attackを改善したMIA手法であり、テキスト$x$中の尤度$p_\theta$の低い単語の集合$\text{Min-k\%}(x)$のみを検出に利用する：
$$ \frac{1}{|\text{Min-k\%}(x)|}\sum_{x_i\in\text{Min-k\%}(x)} p_\theta(x_i|x_1,\ldots,x_{i-1}) > \tau $$
$k=100$%のときはLOSS Attackと等価なMIAである（本論文では$k=20$%を推奨している）。MIN-K% PROBは、以下の仮説に基づく：
- LLMに学習されていないテキストは、尤度が極端に低い単語を含む可能性が高い。
- 既知のテキストは、尤度が極端に低い単語を含む可能性が低い。

尤度の高い単語は"a"や"the"のようにLLMにとって予測しやすい単語であるため、MIAの感度を高めるには尤度の低い単語（=珍しい単語）に着眼すれば良い。これにより、MIN-K% PROBはLOSS Attackよりも高精度で検出可能となる。


# 2. 実装
## 2.1. 実行方法
1. テキスト中の各単語の尤度を計算し、`likelihood/`ディレクトリに保存する。（GPU推奨）
```
python src/calc_likelihood.py
```

2. `.jsonl`ファイルに保存された尤度を用いてMIN-K% PROBを計算し、AUCスコアを標準出力に表示する。
```
python src/eval.py
```

## 2.2. 実験結果
本論文に倣い、私の実装でも評価指標はAUCスコアとし、評価ベンチマークもWIKIMIA（32、64、128、256単語）を用いた。ただし、論文中の実験で使われていない言語モデル（GPT-J、LLaMA-2）も用いて評価した。

実験の結果、MIN-K% PROBは比較手法（LOSS、PPL/zlib、Lowercase）よりも高性能であった。先述の通り、MIN-K% PROBはLOSS Attackを改善していた：

| Model | GPT-J-6B | | | | OPT-6.7B | | | | Pythia-6.9B | | | | LLaMA-2-7B | | | | |
|----------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|------|
| 単語数 | 32 | 64 | 128 | 256 | 32 | 64 | 128 | 256 | 32 | 64 | 128 | 256 | 32 | 64 | 128 | 256 | Avg. |
| LOSS | 0.64 | 0.62 | 0.67 | 0.69 | 0.61 | 0.57 | 0.62 | 0.64 | 0.64 | 0.61 | 0.65 | 0.68 | **0.55** | 0.50 | 0.56 | **0.59** | 0.62 |
| PPL/zlib | 0.65 | 0.63 | 0.68 | 0.69 | 0.61 | 0.58 | 0.64 | 0.65 | 0.64 | 0.62 | 0.67 | 0.70 | **0.55** | **0.51** | **0.57** | **0.59** | 0.62 |
| Lowercase | 0.59 | 0.57 | 0.58 | 0.60 | 0.58 | 0.57 | 0.57 | 0.59 | 0.59 | 0.55 | 0.57 | 0.55 | 0.49 | 0.50 | 0.49 | **0.59** | 0.56 |
| **Min-K% Prob** | **0.67** | **0.66** | **0.70** | **0.71** | **0.62** | **0.60** | **0.67** | **0.67** | **0.66** | **0.64** | **0.69** | **0.71** | 0.51 | 0.50 | 0.56 | 0.58 | **0.63** |